{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ISIBrnoAIMT Encoder with Attention Decoder\n",
    "\n",
    "Encoder was taken from the winner of the [Will Two Do?](https://physionet.org/content/challenge-2021/1.0.3/sources/) challenge [ISIBrnoAIMT](https://www.cinc.org/archives/2021/pdf/CinC2021-014.pdf)\n",
    "Decoder was taken from the [sequence to sequence tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) from Pytorch."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a195e52a52decb2a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, jaccard_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "\n",
    "from models.m04_EcgToText_ISIBrnoAIMT.dataset import *\n",
    "from models.m04_EcgToText_ISIBrnoAIMT.model import *\n",
    "from models.m04_EcgToText_ISIBrnoAIMT.train import *"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-24T05:12:59.709532Z",
     "start_time": "2024-05-24T05:12:51.627102Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T05:12:59.724482Z",
     "start_time": "2024-05-24T05:12:59.710525Z"
    }
   },
   "id": "5b78b990737513dc",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9d10629ccf53312"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################ dataset size: 10% ############################\n",
      "Sampling 1742 (10.0%)\n",
      "0m 8s (- 7m 9s) (1 2.0%) | Train Loss: 1.5908 | Val METEOR: 0.2964\n",
      "0m 19s (- 7m 43s) (2 4.0%) | Train Loss: 0.733 | Val METEOR: 0.3185\n",
      "0m 29s (- 7m 45s) (3 6.0%) | Train Loss: 0.5073 | Val METEOR: 0.3106\n",
      "0m 40s (- 7m 42s) (4 8.0%) | Train Loss: 0.398 | Val METEOR: 0.3525\n",
      "0m 50s (- 7m 34s) (5 10.0%) | Train Loss: 0.3382 | Val METEOR: 0.3463\n",
      "1m 0s (- 7m 26s) (6 12.0%) | Train Loss: 0.3014 | Val METEOR: 0.3107\n",
      "1m 11s (- 7m 17s) (7 14.0%) | Train Loss: 0.2808 | Val METEOR: 0.3572\n",
      "1m 21s (- 7m 8s) (8 16.0%) | Train Loss: 0.2529 | Val METEOR: 0.3488\n",
      "1m 31s (- 6m 58s) (9 18.0%) | Train Loss: 0.2345 | Val METEOR: 0.2951\n",
      "1m 42s (- 6m 49s) (10 20.0%) | Train Loss: 0.2204 | Val METEOR: 0.3602\n",
      "1m 52s (- 6m 39s) (11 22.0%) | Train Loss: 0.2076 | Val METEOR: 0.3643\n",
      "2m 3s (- 6m 30s) (12 24.0%) | Train Loss: 0.2014 | Val METEOR: 0.3295\n",
      "2m 13s (- 6m 19s) (13 26.0%) | Train Loss: 0.1887 | Val METEOR: 0.3751\n",
      "2m 24s (- 6m 10s) (14 28.0%) | Train Loss: 0.1797 | Val METEOR: 0.3618\n",
      "2m 34s (- 5m 59s) (15 30.0%) | Train Loss: 0.1706 | Val METEOR: 0.3437\n",
      "2m 44s (- 5m 49s) (16 32.0%) | Train Loss: 0.1608 | Val METEOR: 0.3913\n",
      "2m 55s (- 5m 40s) (17 34.0%) | Train Loss: 0.1529 | Val METEOR: 0.3952\n",
      "3m 5s (- 5m 30s) (18 36.0%) | Train Loss: 0.1472 | Val METEOR: 0.3972\n",
      "3m 15s (- 5m 19s) (19 38.0%) | Train Loss: 0.1437 | Val METEOR: 0.3865\n",
      "3m 26s (- 5m 9s) (20 40.0%) | Train Loss: 0.1348 | Val METEOR: 0.3937\n",
      "3m 36s (- 4m 59s) (21 42.0%) | Train Loss: 0.1318 | Val METEOR: 0.3871\n",
      "3m 47s (- 4m 48s) (22 44.0%) | Train Loss: 0.1263 | Val METEOR: 0.3526\n",
      "3m 57s (- 4m 38s) (23 46.0%) | Train Loss: 0.1233 | Val METEOR: 0.3701\n",
      "4m 7s (- 4m 28s) (24 48.0%) | Train Loss: 0.1213 | Val METEOR: 0.3931\n",
      "4m 18s (- 4m 18s) (25 50.0%) | Train Loss: 0.1172 | Val METEOR: 0.4074\n",
      "4m 28s (- 4m 7s) (26 52.0%) | Train Loss: 0.1103 | Val METEOR: 0.357\n",
      "4m 38s (- 3m 57s) (27 54.0%) | Train Loss: 0.1102 | Val METEOR: 0.4009\n",
      "4m 49s (- 3m 47s) (28 56.0%) | Train Loss: 0.1058 | Val METEOR: 0.3646\n",
      "4m 59s (- 3m 37s) (29 58.0%) | Train Loss: 0.104 | Val METEOR: 0.3959\n",
      "5m 10s (- 3m 26s) (30 60.0%) | Train Loss: 0.1 | Val METEOR: 0.3956\n",
      "5m 20s (- 3m 16s) (31 62.0%) | Train Loss: 0.0973 | Val METEOR: 0.3986\n",
      "5m 31s (- 3m 6s) (32 64.0%) | Train Loss: 0.093 | Val METEOR: 0.3473\n",
      "5m 41s (- 2m 55s) (33 66.0%) | Train Loss: 0.0914 | Val METEOR: 0.3994\n",
      "5m 51s (- 2m 45s) (34 68.0%) | Train Loss: 0.0902 | Val METEOR: 0.3989\n",
      "6m 1s (- 2m 35s) (35 70.0%) | Train Loss: 0.0858 | Val METEOR: 0.3991\n",
      "No improvement in bleu score for 10 consecutive epochs. Stopping early.\n",
      "############################ dataset size: 20% ############################\n",
      "Sampling 3483 (20.0%)\n",
      "0m 16s (- 13m 28s) (1 2.0%) | Train Loss: 1.254 | Val METEOR: 0.3026\n",
      "0m 34s (- 13m 51s) (2 4.0%) | Train Loss: 0.4888 | Val METEOR: 0.3081\n",
      "0m 53s (- 13m 53s) (3 6.0%) | Train Loss: 0.3476 | Val METEOR: 0.3534\n",
      "1m 11s (- 13m 37s) (4 8.0%) | Train Loss: 0.2935 | Val METEOR: 0.3562\n",
      "1m 29s (- 13m 22s) (5 10.0%) | Train Loss: 0.2635 | Val METEOR: 0.3479\n",
      "1m 47s (- 13m 5s) (6 12.0%) | Train Loss: 0.2412 | Val METEOR: 0.3091\n",
      "2m 5s (- 12m 50s) (7 14.0%) | Train Loss: 0.2217 | Val METEOR: 0.364\n",
      "2m 23s (- 12m 34s) (8 16.0%) | Train Loss: 0.206 | Val METEOR: 0.3723\n",
      "2m 41s (- 12m 17s) (9 18.0%) | Train Loss: 0.1927 | Val METEOR: 0.3808\n",
      "3m 0s (- 12m 0s) (10 20.0%) | Train Loss: 0.1829 | Val METEOR: 0.3673\n",
      "3m 18s (- 11m 42s) (11 22.0%) | Train Loss: 0.1736 | Val METEOR: 0.3255\n",
      "3m 36s (- 11m 25s) (12 24.0%) | Train Loss: 0.1639 | Val METEOR: 0.3608\n",
      "3m 54s (- 11m 7s) (13 26.0%) | Train Loss: 0.1558 | Val METEOR: 0.3506\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_epochs=50\n",
    "hidden_size = 256\n",
    "\n",
    "data_fractions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "for data_fraction in data_fractions:\n",
    "    print(f\"############################ dataset size: {int(data_fraction * 100)}% ############################\")\n",
    "    language, dataloader = get_dataloader(file_path='./data_ptb-xl', batch_size=64, mode='train', device=device, frac=data_fraction)\n",
    "    _, val_dataloader = get_dataloader(file_path='./data_ptb-xl', batch_size=64, mode='val', device=device, _lang=language)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    encoder = NN(num_leads=12,\n",
    "                 hidden_size=hidden_size).to(device)\n",
    "    decoder = AttnDecoderRNN(hidden_size=hidden_size,\n",
    "                             encoder_hidden_size=hidden_size,\n",
    "                             output_size=language.n_words,\n",
    "                             max_len=language.max_len).to(device)\n",
    "    \n",
    "    train(dataloader, val_dataloader, encoder, decoder, criterion, language, n_epochs, size=int(data_fraction*100))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-23T21:42:37.556104Z"
    }
   },
   "id": "7b8bfda8657afe70",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13d46327f50a1c27"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 1742 (10.0%)\n",
      "Sampling 3483 (20.0%)\n",
      "Sampling 5225 (30.0%)\n",
      "Sampling 6967 (40.0%)\n",
      "Sampling 8708 (50.0%)\n",
      "Sampling 10450 (60.0%)\n",
      "Sampling 12192 (70.0%)\n",
      "Sampling 13934 (80.0%)\n",
      "Sampling 15675 (90.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  Dataset  Test Loss      F1  Jaccard  Rouge-1 (p)  Rouge-1 (r)  Rouge-1 (f1)  \\\n0     10%     2.5214  0.0562   0.0363        0.635        0.622         0.607   \n1     20%     2.3084  0.0607   0.0410        0.663        0.705         0.664   \n2     30%     2.4939  0.0624   0.0438        0.674        0.682         0.657   \n3     40%     2.4877  0.0400   0.0267        0.659        0.684         0.650   \n4     50%     2.7262  0.0830   0.0589        0.708        0.698         0.685   \n5     60%     2.6758  0.0462   0.0332        0.670        0.700         0.665   \n6     70%     2.7620  0.0703   0.0512        0.694        0.702         0.680   \n7     80%     2.3599  0.0204   0.0134        0.624        0.674         0.626   \n8     90%     2.8080  0.0764   0.0554        0.723        0.747         0.718   \n\n   Rouge-2 (p)  Rouge-2 (r)  Rouge-2 (f1)  Rouge-L (p)  Rouge-L (r)  \\\n0        0.500        0.490         0.477        0.632        0.619   \n1        0.542        0.569         0.539        0.661        0.703   \n2        0.549        0.548         0.530        0.671        0.679   \n3        0.529        0.540         0.517        0.655        0.680   \n4        0.589        0.579         0.569        0.705        0.694   \n5        0.544        0.559         0.534        0.667        0.697   \n6        0.571        0.573         0.556        0.691        0.699   \n7        0.491        0.520         0.486        0.622        0.671   \n8        0.617        0.635         0.611        0.720        0.744   \n\n   Rouge-L (f1)  METEOR  \n0         0.604   0.558  \n1         0.661   0.594  \n2         0.654   0.590  \n3         0.647   0.578  \n4         0.682   0.636  \n5         0.661   0.588  \n6         0.677   0.617  \n7         0.623   0.538  \n8         0.715   0.661  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset</th>\n      <th>Test Loss</th>\n      <th>F1</th>\n      <th>Jaccard</th>\n      <th>Rouge-1 (p)</th>\n      <th>Rouge-1 (r)</th>\n      <th>Rouge-1 (f1)</th>\n      <th>Rouge-2 (p)</th>\n      <th>Rouge-2 (r)</th>\n      <th>Rouge-2 (f1)</th>\n      <th>Rouge-L (p)</th>\n      <th>Rouge-L (r)</th>\n      <th>Rouge-L (f1)</th>\n      <th>METEOR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10%</td>\n      <td>2.5214</td>\n      <td>0.0562</td>\n      <td>0.0363</td>\n      <td>0.635</td>\n      <td>0.622</td>\n      <td>0.607</td>\n      <td>0.500</td>\n      <td>0.490</td>\n      <td>0.477</td>\n      <td>0.632</td>\n      <td>0.619</td>\n      <td>0.604</td>\n      <td>0.558</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20%</td>\n      <td>2.3084</td>\n      <td>0.0607</td>\n      <td>0.0410</td>\n      <td>0.663</td>\n      <td>0.705</td>\n      <td>0.664</td>\n      <td>0.542</td>\n      <td>0.569</td>\n      <td>0.539</td>\n      <td>0.661</td>\n      <td>0.703</td>\n      <td>0.661</td>\n      <td>0.594</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30%</td>\n      <td>2.4939</td>\n      <td>0.0624</td>\n      <td>0.0438</td>\n      <td>0.674</td>\n      <td>0.682</td>\n      <td>0.657</td>\n      <td>0.549</td>\n      <td>0.548</td>\n      <td>0.530</td>\n      <td>0.671</td>\n      <td>0.679</td>\n      <td>0.654</td>\n      <td>0.590</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40%</td>\n      <td>2.4877</td>\n      <td>0.0400</td>\n      <td>0.0267</td>\n      <td>0.659</td>\n      <td>0.684</td>\n      <td>0.650</td>\n      <td>0.529</td>\n      <td>0.540</td>\n      <td>0.517</td>\n      <td>0.655</td>\n      <td>0.680</td>\n      <td>0.647</td>\n      <td>0.578</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50%</td>\n      <td>2.7262</td>\n      <td>0.0830</td>\n      <td>0.0589</td>\n      <td>0.708</td>\n      <td>0.698</td>\n      <td>0.685</td>\n      <td>0.589</td>\n      <td>0.579</td>\n      <td>0.569</td>\n      <td>0.705</td>\n      <td>0.694</td>\n      <td>0.682</td>\n      <td>0.636</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>60%</td>\n      <td>2.6758</td>\n      <td>0.0462</td>\n      <td>0.0332</td>\n      <td>0.670</td>\n      <td>0.700</td>\n      <td>0.665</td>\n      <td>0.544</td>\n      <td>0.559</td>\n      <td>0.534</td>\n      <td>0.667</td>\n      <td>0.697</td>\n      <td>0.661</td>\n      <td>0.588</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>70%</td>\n      <td>2.7620</td>\n      <td>0.0703</td>\n      <td>0.0512</td>\n      <td>0.694</td>\n      <td>0.702</td>\n      <td>0.680</td>\n      <td>0.571</td>\n      <td>0.573</td>\n      <td>0.556</td>\n      <td>0.691</td>\n      <td>0.699</td>\n      <td>0.677</td>\n      <td>0.617</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>80%</td>\n      <td>2.3599</td>\n      <td>0.0204</td>\n      <td>0.0134</td>\n      <td>0.624</td>\n      <td>0.674</td>\n      <td>0.626</td>\n      <td>0.491</td>\n      <td>0.520</td>\n      <td>0.486</td>\n      <td>0.622</td>\n      <td>0.671</td>\n      <td>0.623</td>\n      <td>0.538</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>90%</td>\n      <td>2.8080</td>\n      <td>0.0764</td>\n      <td>0.0554</td>\n      <td>0.723</td>\n      <td>0.747</td>\n      <td>0.718</td>\n      <td>0.617</td>\n      <td>0.635</td>\n      <td>0.611</td>\n      <td>0.720</td>\n      <td>0.744</td>\n      <td>0.715</td>\n      <td>0.661</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "hidden_size = 256\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "data_fractions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for data_fraction in data_fractions:\n",
    "    language, dataloader = get_dataloader(file_path='./data_ptb-xl', batch_size=64, mode='train', device=device, frac=data_fraction)\n",
    "    _, test_dataloader = get_dataloader(file_path='./data_ptb-xl', batch_size=64, mode='test', device=device, _lang=language)\n",
    "    \n",
    "    encoder = NN(num_leads=12,\n",
    "                 hidden_size=hidden_size).to(device)\n",
    "    decoder = AttnDecoderRNN(hidden_size=hidden_size,\n",
    "                             encoder_hidden_size=hidden_size,\n",
    "                             output_size=language.n_words,\n",
    "                             max_len=language.max_len).to(device)\n",
    "    \n",
    "    encoder.load_state_dict(torch.load(f'./models/m04_EcgToText_ISIBrnoAIMT/models_with_reduced_dataset/Encoder_{int(data_fraction*100)}.pth'))\n",
    "    decoder.load_state_dict(torch.load(f'./models/m04_EcgToText_ISIBrnoAIMT/models_with_reduced_dataset/Decoder_{int(data_fraction*100)}.pth'))\n",
    "    \n",
    "    total_loss, f1, jaccard, rouge, meteor = validate_epoch(dataloader, encoder, decoder, criterion, language)\n",
    "\n",
    "    results.append({\n",
    "        \"Dataset\": f\"{int(data_fraction*100)}%\",\n",
    "        \"Test Loss\": round(total_loss, 4),\n",
    "        \"F1\": round(f1, 4),\n",
    "        \"Jaccard\": round(jaccard, 4),\n",
    "        \"Rouge-1 (p)\": round(rouge[\"rouge-1\"][\"p\"], 3),\n",
    "        \"Rouge-1 (r)\": round(rouge[\"rouge-1\"][\"r\"], 3),\n",
    "        \"Rouge-1 (f1)\": round(rouge[\"rouge-1\"][\"f\"], 3),\n",
    "        \"Rouge-2 (p)\": round(rouge[\"rouge-2\"][\"p\"], 3),\n",
    "        \"Rouge-2 (r)\": round(rouge[\"rouge-2\"][\"r\"], 3),\n",
    "        \"Rouge-2 (f1)\": round(rouge[\"rouge-2\"][\"f\"], 3),\n",
    "        \"Rouge-L (p)\": round(rouge[\"rouge-l\"][\"p\"], 3),\n",
    "        \"Rouge-L (r)\": round(rouge[\"rouge-l\"][\"r\"], 3),\n",
    "        \"Rouge-L (f1)\": round(rouge[\"rouge-l\"][\"f\"], 3),\n",
    "        \"METEOR\": round(meteor, 3)\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-24T07:19:49.957331Z",
     "start_time": "2024-05-24T07:14:36.540654Z"
    }
   },
   "id": "60dbbbcfc31e7246",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "db8d0fe68802ee3c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
